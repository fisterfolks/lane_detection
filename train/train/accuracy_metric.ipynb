{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import importlib\n",
    "import random\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "HEIGHT = 512\n",
    "WIDTH = 904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = importlib.import_module(\"erfnet\")\n",
    "model = model_file.Net(NUM_CLASSES)\n",
    "model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/yerzh/cv/project/model/erfnet_pytorch/save/model_best.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path='/home/yerzh/cv/project/train_set/label_data_0531.json'\n",
    "root_dir='/home/yerzh/cv/project/train_set/'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "op_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "def accuracy(model, json_path, root_dir, device, op_transforms):\n",
    "    json_gt = [json.loads(line) for line in open(json_path)]\n",
    "    for gt in json_gt:\n",
    "        gt_lanes = gt['lanes']\n",
    "        y_samples = gt['h_samples']\n",
    "        raw_file = gt['raw_file']\n",
    "        img = cv2.imread(root_dir + raw_file)\n",
    "        gt_lanes_vis = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]\n",
    "        mask = np.zeros_like(img[:,:,0])\n",
    "        cv2.polylines(mask, np.int32([gt_lanes_vis[0]]), isClosed=False,color=255, thickness=5)\n",
    "        cv2.polylines(mask, np.int32([gt_lanes_vis[1]]), isClosed=False,color=255, thickness=5)\n",
    "        im_tensor = torch.unsqueeze(op_transforms(img), dim=0)\n",
    "        im_tensor = im_tensor.to(device)\n",
    "        model = model.to(device)\n",
    "        with torch.no_grad():\n",
    "            model = model.eval()\n",
    "            out = model(im_tensor)\n",
    "        out = out.max(dim=1)[1]\n",
    "        out_np = out.cpu().numpy()[0].reshape(mask.shape)\n",
    "        lines = cv2.HoughLinesP(out_np.astype(np.uint8), 1, np.pi/180, 30, maxLineGap=200)\n",
    "        dmy = out_np.astype(np.uint8).copy()\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(dmy, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "        start=0\n",
    "        end=0\n",
    "        start2=0\n",
    "        end2=0\n",
    "        for i in range(mask.shape[0]):\n",
    "            if len(np.unique(mask[i]))==1:\n",
    "                continue\n",
    "            flag=0\n",
    "            dist=0\n",
    "            for j in range(2,mask.shape[1]-2):\n",
    "                if mask[i][j-2]!=0 and mask[i][j-1]!=0 and mask[i][j]!=0 and mask[i][j+1]==0:\n",
    "                    dist=0\n",
    "                    start=end\n",
    "                elif mask[i][j-1]==0 and mask[i][j]!=0 and mask[i][j+1]!=0 and mask[i][j+2]!=0:\n",
    "                    if flag==1:\n",
    "                        break\n",
    "                    flag+=1\n",
    "                dist+=1\n",
    "                end+=1\n",
    "            flag2=0\n",
    "            dist2=0\n",
    "            for j in range(2,dmy.shape[1]-2):\n",
    "                if dmy[i][j-2]!=0 and dmy[i][j-1]!=0 and dmy[i][j]!=0 and dmy[i][j+1]==0:\n",
    "                    dist2=0\n",
    "                    start2=end2\n",
    "                elif dmy[i][j-1]==0 and dmy[i][j]!=0 and dmy[i][j+1]!=0 and dmy[i][j+2]!=0:\n",
    "                    if flag2==1:\n",
    "                        break\n",
    "                    flag2+=1\n",
    "                dist2+=1\n",
    "                end2+=1\n",
    "            if np.abs(dist-dist2)<11 and np.abs(start-start2)<6 and np.abs(end-end2)<6:\n",
    "                scores.append(1)\n",
    "            else:\n",
    "                scores.append(0)\n",
    "    return np.array(scores).sum()/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy(model, json_path, root_dir, device, op_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
